{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd39931",
   "metadata": {},
   "source": [
    "# Predicting the Popularity of Music Records\n",
    "# Student: Majid Lagzian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88189ad8",
   "metadata": {},
   "source": [
    "## 1.\tFit a logistic regression model using all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f86c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>songtitle</th>\n",
       "      <th>artistname</th>\n",
       "      <th>songID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>timesignature</th>\n",
       "      <th>timesignature_confidence</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>tempo_confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>timbre_7_max</th>\n",
       "      <th>timbre_8_min</th>\n",
       "      <th>timbre_8_max</th>\n",
       "      <th>timbre_9_min</th>\n",
       "      <th>timbre_9_max</th>\n",
       "      <th>timbre_10_min</th>\n",
       "      <th>timbre_10_max</th>\n",
       "      <th>timbre_11_min</th>\n",
       "      <th>timbre_11_max</th>\n",
       "      <th>Top10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>This Is the House That Doubt Built</td>\n",
       "      <td>A Day to Remember</td>\n",
       "      <td>SOBGGAB12C5664F054</td>\n",
       "      <td>AROBSHL1187B9AFB01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.853</td>\n",
       "      <td>-4.262</td>\n",
       "      <td>91.525</td>\n",
       "      <td>0.953</td>\n",
       "      <td>...</td>\n",
       "      <td>82.475</td>\n",
       "      <td>-52.025</td>\n",
       "      <td>39.116</td>\n",
       "      <td>-35.368</td>\n",
       "      <td>71.642</td>\n",
       "      <td>-126.440</td>\n",
       "      <td>18.658</td>\n",
       "      <td>-44.770</td>\n",
       "      <td>25.989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Sticks &amp; Bricks</td>\n",
       "      <td>A Day to Remember</td>\n",
       "      <td>SOPAQHU1315CD47F31</td>\n",
       "      <td>AROBSHL1187B9AFB01</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-4.051</td>\n",
       "      <td>140.048</td>\n",
       "      <td>0.921</td>\n",
       "      <td>...</td>\n",
       "      <td>106.918</td>\n",
       "      <td>-61.320</td>\n",
       "      <td>35.378</td>\n",
       "      <td>-81.928</td>\n",
       "      <td>74.574</td>\n",
       "      <td>-103.808</td>\n",
       "      <td>121.935</td>\n",
       "      <td>-38.892</td>\n",
       "      <td>22.513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>All I Want</td>\n",
       "      <td>A Day to Remember</td>\n",
       "      <td>SOOIZOU1376E7C6386</td>\n",
       "      <td>AROBSHL1187B9AFB01</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-3.571</td>\n",
       "      <td>160.512</td>\n",
       "      <td>0.489</td>\n",
       "      <td>...</td>\n",
       "      <td>80.621</td>\n",
       "      <td>-59.773</td>\n",
       "      <td>45.979</td>\n",
       "      <td>-46.293</td>\n",
       "      <td>59.904</td>\n",
       "      <td>-108.313</td>\n",
       "      <td>33.300</td>\n",
       "      <td>-43.733</td>\n",
       "      <td>25.744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>It's Complicated</td>\n",
       "      <td>A Day to Remember</td>\n",
       "      <td>SODRYWD1315CD49DBE</td>\n",
       "      <td>AROBSHL1187B9AFB01</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-3.815</td>\n",
       "      <td>97.525</td>\n",
       "      <td>0.794</td>\n",
       "      <td>...</td>\n",
       "      <td>96.675</td>\n",
       "      <td>-78.660</td>\n",
       "      <td>41.088</td>\n",
       "      <td>-49.194</td>\n",
       "      <td>95.440</td>\n",
       "      <td>-102.676</td>\n",
       "      <td>46.422</td>\n",
       "      <td>-59.439</td>\n",
       "      <td>37.082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>2nd Sucks</td>\n",
       "      <td>A Day to Remember</td>\n",
       "      <td>SOICMQB1315CD46EE3</td>\n",
       "      <td>AROBSHL1187B9AFB01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.788</td>\n",
       "      <td>-4.707</td>\n",
       "      <td>140.053</td>\n",
       "      <td>0.286</td>\n",
       "      <td>...</td>\n",
       "      <td>110.332</td>\n",
       "      <td>-56.450</td>\n",
       "      <td>37.555</td>\n",
       "      <td>-48.588</td>\n",
       "      <td>67.570</td>\n",
       "      <td>-52.796</td>\n",
       "      <td>22.888</td>\n",
       "      <td>-50.414</td>\n",
       "      <td>32.758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                           songtitle         artistname  \\\n",
       "0  2010  This Is the House That Doubt Built  A Day to Remember   \n",
       "1  2010                     Sticks & Bricks  A Day to Remember   \n",
       "2  2010                          All I Want  A Day to Remember   \n",
       "3  2010                    It's Complicated  A Day to Remember   \n",
       "4  2010                           2nd Sucks  A Day to Remember   \n",
       "\n",
       "               songID            artistID  timesignature  \\\n",
       "0  SOBGGAB12C5664F054  AROBSHL1187B9AFB01              3   \n",
       "1  SOPAQHU1315CD47F31  AROBSHL1187B9AFB01              4   \n",
       "2  SOOIZOU1376E7C6386  AROBSHL1187B9AFB01              4   \n",
       "3  SODRYWD1315CD49DBE  AROBSHL1187B9AFB01              4   \n",
       "4  SOICMQB1315CD46EE3  AROBSHL1187B9AFB01              4   \n",
       "\n",
       "   timesignature_confidence  loudness    tempo  tempo_confidence  ...  \\\n",
       "0                     0.853    -4.262   91.525             0.953  ...   \n",
       "1                     1.000    -4.051  140.048             0.921  ...   \n",
       "2                     1.000    -3.571  160.512             0.489  ...   \n",
       "3                     1.000    -3.815   97.525             0.794  ...   \n",
       "4                     0.788    -4.707  140.053             0.286  ...   \n",
       "\n",
       "   timbre_7_max  timbre_8_min  timbre_8_max  timbre_9_min  timbre_9_max  \\\n",
       "0        82.475       -52.025        39.116       -35.368        71.642   \n",
       "1       106.918       -61.320        35.378       -81.928        74.574   \n",
       "2        80.621       -59.773        45.979       -46.293        59.904   \n",
       "3        96.675       -78.660        41.088       -49.194        95.440   \n",
       "4       110.332       -56.450        37.555       -48.588        67.570   \n",
       "\n",
       "   timbre_10_min  timbre_10_max  timbre_11_min  timbre_11_max  Top10  \n",
       "0       -126.440         18.658        -44.770         25.989      0  \n",
       "1       -103.808        121.935        -38.892         22.513      0  \n",
       "2       -108.313         33.300        -43.733         25.744      0  \n",
       "3       -102.676         46.422        -59.439         37.082      0  \n",
       "4        -52.796         22.888        -50.414         32.758      0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First we import the required libraries\n",
    "#Also, we import our data from the appropriate file\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "data_path = osp.join(osp.curdir,'MusicData.csv')\n",
    "music_data = pd.read_csv(data_path, encoding='latin-1')\n",
    "music_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e73204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>timesignature</th>\n",
       "      <th>timesignature_confidence</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>tempo_confidence</th>\n",
       "      <th>key</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>energy</th>\n",
       "      <th>pitch</th>\n",
       "      <th>...</th>\n",
       "      <th>timbre_7_max</th>\n",
       "      <th>timbre_8_min</th>\n",
       "      <th>timbre_8_max</th>\n",
       "      <th>timbre_9_min</th>\n",
       "      <th>timbre_9_max</th>\n",
       "      <th>timbre_10_min</th>\n",
       "      <th>timbre_10_max</th>\n",
       "      <th>timbre_11_min</th>\n",
       "      <th>timbre_11_max</th>\n",
       "      <th>Top10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "      <td>7574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2001.455902</td>\n",
       "      <td>3.893979</td>\n",
       "      <td>0.853307</td>\n",
       "      <td>-8.817262</td>\n",
       "      <td>107.348267</td>\n",
       "      <td>0.622866</td>\n",
       "      <td>5.384605</td>\n",
       "      <td>0.433843</td>\n",
       "      <td>0.675471</td>\n",
       "      <td>0.010817</td>\n",
       "      <td>...</td>\n",
       "      <td>95.653221</td>\n",
       "      <td>-63.703984</td>\n",
       "      <td>50.057489</td>\n",
       "      <td>-59.515016</td>\n",
       "      <td>68.028067</td>\n",
       "      <td>-87.340055</td>\n",
       "      <td>55.520722</td>\n",
       "      <td>-50.868457</td>\n",
       "      <td>47.490774</td>\n",
       "      <td>0.147742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.815223</td>\n",
       "      <td>0.532561</td>\n",
       "      <td>0.243748</td>\n",
       "      <td>4.377079</td>\n",
       "      <td>24.665030</td>\n",
       "      <td>0.304656</td>\n",
       "      <td>3.572579</td>\n",
       "      <td>0.273826</td>\n",
       "      <td>0.243473</td>\n",
       "      <td>0.013671</td>\n",
       "      <td>...</td>\n",
       "      <td>26.859726</td>\n",
       "      <td>15.970244</td>\n",
       "      <td>14.463524</td>\n",
       "      <td>17.190527</td>\n",
       "      <td>20.381321</td>\n",
       "      <td>30.464274</td>\n",
       "      <td>23.549473</td>\n",
       "      <td>11.701530</td>\n",
       "      <td>12.463966</td>\n",
       "      <td>0.354868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1990.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-42.451000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.699000</td>\n",
       "      <td>-158.756000</td>\n",
       "      <td>-25.955000</td>\n",
       "      <td>-149.507000</td>\n",
       "      <td>8.415000</td>\n",
       "      <td>-208.819000</td>\n",
       "      <td>-6.359000</td>\n",
       "      <td>-145.599000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1997.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.819250</td>\n",
       "      <td>-10.847000</td>\n",
       "      <td>88.860250</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.500138</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.498000</td>\n",
       "      <td>-73.050750</td>\n",
       "      <td>40.584500</td>\n",
       "      <td>-70.282500</td>\n",
       "      <td>53.037250</td>\n",
       "      <td>-105.130250</td>\n",
       "      <td>39.196000</td>\n",
       "      <td>-58.058000</td>\n",
       "      <td>38.975250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>-7.649000</td>\n",
       "      <td>103.268000</td>\n",
       "      <td>0.701500</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.718160</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>...</td>\n",
       "      <td>94.632500</td>\n",
       "      <td>-62.661500</td>\n",
       "      <td>49.220000</td>\n",
       "      <td>-58.650000</td>\n",
       "      <td>65.935000</td>\n",
       "      <td>-83.074000</td>\n",
       "      <td>50.895000</td>\n",
       "      <td>-50.892500</td>\n",
       "      <td>46.437500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2006.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.640000</td>\n",
       "      <td>124.800500</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.887396</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>...</td>\n",
       "      <td>112.708250</td>\n",
       "      <td>-52.982750</td>\n",
       "      <td>58.462000</td>\n",
       "      <td>-47.699750</td>\n",
       "      <td>81.267000</td>\n",
       "      <td>-64.518000</td>\n",
       "      <td>66.593000</td>\n",
       "      <td>-43.292250</td>\n",
       "      <td>55.030250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.305000</td>\n",
       "      <td>244.307000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998492</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>...</td>\n",
       "      <td>214.819000</td>\n",
       "      <td>-2.382000</td>\n",
       "      <td>144.985000</td>\n",
       "      <td>1.140000</td>\n",
       "      <td>161.518000</td>\n",
       "      <td>-10.640000</td>\n",
       "      <td>192.417000</td>\n",
       "      <td>-6.497000</td>\n",
       "      <td>110.272000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              year  timesignature  timesignature_confidence     loudness  \\\n",
       "count  7574.000000    7574.000000               7574.000000  7574.000000   \n",
       "mean   2001.455902       3.893979                  0.853307    -8.817262   \n",
       "std       5.815223       0.532561                  0.243748     4.377079   \n",
       "min    1990.000000       0.000000                  0.000000   -42.451000   \n",
       "25%    1997.000000       4.000000                  0.819250   -10.847000   \n",
       "50%    2002.000000       4.000000                  0.979000    -7.649000   \n",
       "75%    2006.000000       4.000000                  1.000000    -5.640000   \n",
       "max    2010.000000       7.000000                  1.000000     1.305000   \n",
       "\n",
       "             tempo  tempo_confidence          key  key_confidence  \\\n",
       "count  7574.000000       7574.000000  7574.000000     7574.000000   \n",
       "mean    107.348267          0.622866     5.384605        0.433843   \n",
       "std      24.665030          0.304656     3.572579        0.273826   \n",
       "min       0.000000          0.000000     0.000000        0.000000   \n",
       "25%      88.860250          0.372000     2.000000        0.204000   \n",
       "50%     103.268000          0.701500     6.000000        0.451500   \n",
       "75%     124.800500          0.892000     9.000000        0.646000   \n",
       "max     244.307000          1.000000    11.000000        1.000000   \n",
       "\n",
       "            energy        pitch  ...  timbre_7_max  timbre_8_min  \\\n",
       "count  7574.000000  7574.000000  ...   7574.000000   7574.000000   \n",
       "mean      0.675471     0.010817  ...     95.653221    -63.703984   \n",
       "std       0.243473     0.013671  ...     26.859726     15.970244   \n",
       "min       0.000020     0.000000  ...     15.699000   -158.756000   \n",
       "25%       0.500138     0.003000  ...     76.498000    -73.050750   \n",
       "50%       0.718160     0.007000  ...     94.632500    -62.661500   \n",
       "75%       0.887396     0.014000  ...    112.708250    -52.982750   \n",
       "max       0.998492     0.541000  ...    214.819000     -2.382000   \n",
       "\n",
       "       timbre_8_max  timbre_9_min  timbre_9_max  timbre_10_min  timbre_10_max  \\\n",
       "count   7574.000000   7574.000000   7574.000000    7574.000000    7574.000000   \n",
       "mean      50.057489    -59.515016     68.028067     -87.340055      55.520722   \n",
       "std       14.463524     17.190527     20.381321      30.464274      23.549473   \n",
       "min      -25.955000   -149.507000      8.415000    -208.819000      -6.359000   \n",
       "25%       40.584500    -70.282500     53.037250    -105.130250      39.196000   \n",
       "50%       49.220000    -58.650000     65.935000     -83.074000      50.895000   \n",
       "75%       58.462000    -47.699750     81.267000     -64.518000      66.593000   \n",
       "max      144.985000      1.140000    161.518000     -10.640000     192.417000   \n",
       "\n",
       "       timbre_11_min  timbre_11_max        Top10  \n",
       "count    7574.000000    7574.000000  7574.000000  \n",
       "mean      -50.868457      47.490774     0.147742  \n",
       "std        11.701530      12.463966     0.354868  \n",
       "min      -145.599000       7.200000     0.000000  \n",
       "25%       -58.058000      38.975250     0.000000  \n",
       "50%       -50.892500      46.437500     0.000000  \n",
       "75%       -43.292250      55.030250     0.000000  \n",
       "max        -6.497000     110.272000     1.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we conduct a quick data exploration to see if there is any missing value, outlier, etc.\n",
    "music_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dc2ae7",
   "metadata": {},
   "source": [
    "Now we split the dataset to a training set of all the songs released during or prior to 2009, and a test set of all the song releases in 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee107af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We filter rows where year is less than or equal to 2009 for training set\n",
    "SongsTrain = music_data[music_data['year'] <= 2009]\n",
    "\n",
    "# We filter rows where year is 2010 for testing set\n",
    "SongsTest = music_data[music_data['year'] == 2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47282c58",
   "metadata": {},
   "source": [
    "Now we need to exclude some of the variables from being used as independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8f41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonvars = [\"year\", \"songtitle\", \"artistname\", \"songID\", \"artistID\"]\n",
    "SongsTrain = SongsTrain.drop(nonvars, axis=1)\n",
    "SongsTest = SongsTest.drop(nonvars, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a679b6d",
   "metadata": {},
   "source": [
    "Now we can build the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d988e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train=SongsTrain.drop(['Top10'],axis=1)\n",
    "y_train=SongsTrain['Top10']\n",
    "X_test=SongsTest.drop(['Top10'],axis=1)\n",
    "y_test=SongsTest['Top10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "605d0a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.335207\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Top10   No. Observations:                 7201\n",
      "Model:                          Logit   Df Residuals:                     7168\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sun, 14 May 2023   Pseudo R-squ.:                  0.1977\n",
      "Time:                        00:21:38   Log-Likelihood:                -2413.8\n",
      "converged:                       True   LL-Null:                       -3008.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.373e-229\n",
      "============================================================================================\n",
      "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "timesignature                0.2818      0.089      3.162      0.002       0.107       0.457\n",
      "timesignature_confidence     0.7315      0.196      3.733      0.000       0.347       1.116\n",
      "loudness                     0.0879      0.012      7.119      0.000       0.064       0.112\n",
      "tempo                        0.0023      0.002      1.404      0.160      -0.001       0.006\n",
      "tempo_confidence             0.5823      0.142      4.112      0.000       0.305       0.860\n",
      "key                          0.0201      0.010      1.950      0.051   -9.96e-05       0.040\n",
      "key_confidence               0.3164      0.140      2.258      0.024       0.042       0.591\n",
      "energy                      -0.6730      0.291     -2.314      0.021      -1.243      -0.103\n",
      "pitch                      -43.1605      6.800     -6.347      0.000     -56.489     -29.832\n",
      "timbre_0_min                 0.0264      0.004      6.259      0.000       0.018       0.035\n",
      "timbre_0_max                -0.1379      0.009    -15.595      0.000      -0.155      -0.121\n",
      "timbre_1_min                 0.0068      0.001      8.783      0.000       0.005       0.008\n",
      "timbre_1_max                -0.0006      0.001     -0.833      0.405      -0.002       0.001\n",
      "timbre_2_min                -0.0018      0.001     -1.566      0.117      -0.004       0.000\n",
      "timbre_2_max                 0.0003      0.001      0.377      0.706      -0.001       0.002\n",
      "timbre_3_min                 0.0007      0.001      1.166      0.244      -0.000       0.002\n",
      "timbre_3_max                -0.0026      0.001     -4.631      0.000      -0.004      -0.002\n",
      "timbre_4_min                 0.0086      0.002      4.406      0.000       0.005       0.012\n",
      "timbre_4_max                 0.0063      0.002      4.117      0.000       0.003       0.009\n",
      "timbre_5_min                -0.0057      0.001     -4.537      0.000      -0.008      -0.003\n",
      "timbre_5_max                 0.0005      0.001      0.613      0.540      -0.001       0.002\n",
      "timbre_6_min                -0.0167      0.002     -7.434      0.000      -0.021      -0.012\n",
      "timbre_6_max                 0.0039      0.002      1.817      0.069      -0.000       0.008\n",
      "timbre_7_min                -0.0047      0.002     -2.685      0.007      -0.008      -0.001\n",
      "timbre_7_max                -0.0031      0.002     -1.701      0.089      -0.007       0.000\n",
      "timbre_8_min                 0.0038      0.003      1.348      0.178      -0.002       0.009\n",
      "timbre_8_max                 0.0076      0.003      2.570      0.010       0.002       0.013\n",
      "timbre_9_min              -2.37e-05      0.003     -0.008      0.994      -0.006       0.006\n",
      "timbre_9_max                 0.0035      0.002      1.477      0.140      -0.001       0.008\n",
      "timbre_10_min                0.0033      0.002      1.832      0.067      -0.000       0.007\n",
      "timbre_10_max                0.0069      0.002      3.951      0.000       0.003       0.010\n",
      "timbre_11_min               -0.0295      0.004     -8.121      0.000      -0.037      -0.022\n",
      "timbre_11_max                0.0206      0.003      6.129      0.000       0.014       0.027\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Now we fit a logistic regression model to the training data\n",
    "model = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d8d0a0",
   "metadata": {},
   "source": [
    "## 2. Predict the popularity of records in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc0070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c275a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's calculate the confusion matrix and the accuracy of models\n",
    "def logreg_evaluation(y_hat):\n",
    "    y_hatBin = (y_hat >= 0.15).astype(int)\n",
    "    confusionMatrix = confusion_matrix(y_test, y_hatBin)\n",
    "    print(confusionMatrix)\n",
    "    \n",
    "    count_correct = confusionMatrix[0,0] + confusionMatrix[1,1]\n",
    "    count_wrong = confusionMatrix[0,1] + confusionMatrix[1,0]\n",
    "    accuracy_rate=count_correct/(count_correct+count_wrong)\n",
    "    print(\"Accuracy of the model is: \", accuracy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6538d4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[224  90]\n",
      " [ 16  43]]\n",
      "Accuracy of the model is:  0.7158176943699732\n"
     ]
    }
   ],
   "source": [
    "logreg_evaluation(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c018330",
   "metadata": {},
   "source": [
    "## 3. Generate the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c825c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "auc = roc_auc_score(y_test, y_hat)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c3fe35",
   "metadata": {},
   "source": [
    "## 4. Improve the prediction performance of your model. Explain all steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1848936",
   "metadata": {},
   "source": [
    "Let's first try using SelectFromModel for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00cc1453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "\n",
    "# First, we define feature selector using logistic regression\n",
    "selector = SelectFromModel(logreg, threshold='1.25*median')\n",
    "\n",
    "# Then, we fit selector to training data\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Now, we transform training and test data to include only selected features\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Finally, we fit logistic regression model on selected features\n",
    "model2 = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "model2.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28021e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[313   1]\n",
      " [ 51   8]]\n",
      "Accuracy of the model is:  0.8605898123324397\n"
     ]
    }
   ],
   "source": [
    "y_hat2 = model2.predict(X_test_selected)\n",
    "logreg_evaluation(y_hat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7f4c4",
   "metadata": {},
   "source": [
    "This is a good improvement in the model accuracy. But let's do one more step and perform Lasso and Ridge regularization to see if the logistic regression can be further improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f046b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso score: 0.863\n",
      "Ridge score: 0.863\n",
      "Logrig score: 0.861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# First, we define the pipeline with Lasso regularization\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('feature_selection', SelectFromModel(LogisticRegressionCV(penalty='l1', Cs=10, solver='liblinear', cv=5),threshold='1.25*median')),\n",
    "    ('model', LogisticRegressionCV(penalty='l2', Cs=10, solver='liblinear', cv=5))\n",
    "])\n",
    "\n",
    "# Next, we define the pipeline with Ridge regularization\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('feature_selection', SelectFromModel(LogisticRegressionCV(penalty='l2', Cs=10, solver='liblinear', cv=5),threshold='1.25*median')),\n",
    "    ('model', LogisticRegressionCV(penalty='l2', Cs=10, solver='liblinear', cv=5))\n",
    "])\n",
    "\n",
    "# We fit the pipelines on the training data and evaluate the models on the test date\n",
    "lasso_pipeline.fit(X_train, y_train)\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "\n",
    "lasso_score = lasso_pipeline.score(X_test, y_test)\n",
    "ridge_score = ridge_pipeline.score(X_test, y_test)\n",
    "#We also evaluate the the previous model we developed\n",
    "logrig_score=model2.score(X_test_selected, y_test)\n",
    "\n",
    "# print the scores\n",
    "print(\"Lasso score: {:.3f}\".format(lasso_score))\n",
    "print(\"Ridge score: {:.3f}\".format(ridge_score))\n",
    "print(\"Logrig score: {:.3f}\".format(logrig_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43628f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[310   4]\n",
      " [ 47  12]]\n",
      "Accuracy of the model is:  0.8632707774798928\n"
     ]
    }
   ],
   "source": [
    "lasso_y_hat = lasso_pipeline.predict(X_test)\n",
    "logreg_evaluation(lasso_y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95113bc",
   "metadata": {},
   "source": [
    "Therefore, Lasso regularization gives us the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "490aa58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "timesignature_confidence: 0.234\n",
      "loudness: 1.320\n",
      "energy: -0.310\n",
      "pitch: -0.668\n",
      "timbre_0_min: 0.184\n",
      "timbre_0_max: -1.367\n",
      "timbre_1_min: 0.396\n",
      "timbre_3_max: -0.367\n",
      "timbre_4_min: 0.205\n",
      "timbre_4_max: 0.231\n",
      "timbre_5_min: -0.252\n",
      "timbre_6_min: -0.369\n",
      "timbre_11_min: -0.332\n",
      "timbre_11_max: 0.270\n"
     ]
    }
   ],
   "source": [
    "# Let's retrieve the names and coefficients of the selected features\n",
    "selected_features = X_train.columns[lasso_pipeline.named_steps['feature_selection'].get_support()]\n",
    "\n",
    "# Get the coefficients of the logistic regression model from the pipeline's model object\n",
    "coef = lasso_pipeline.named_steps['model'].coef_[0]\n",
    "\n",
    "# Print the coefficients for each selected feature\n",
    "print(\"Coefficients:\")\n",
    "for feature, coef in zip(selected_features, coef):\n",
    "    print(f\"{feature}: {coef:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813a84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
